{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dimension reduction\n",
    "\n",
    "##### In this step, we perform dimension reduction of the interpolated trajectories using Probabilistic PCA (PPCA). PPCA considers the model $x \\sim wz + \\text{noise}$ and defines prior distributions over $z$, $w$, and $\\text{noise}$ ($p(\\theta)$), along with the joint distribution $p(x,\\theta)$. We've implemented and deployed the ADVI algorithm to find the parameters of the variational distribution $q(\\mu, \\omega)$ approximating $p(\\theta | x)$, enabling the projection of $x$ into a lower dimension $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0- Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from src.advi_fcts import * \n",
    "from src.df_processing import * \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and extract trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataframe dimension (ie. number of trajectories)\n",
    "nb_points = 195\n",
    "\n",
    "# Load dataset\n",
    "x = pd.read_csv('df/interpolation/interpolation_'+str(nb_points)+'.csv')\n",
    "\n",
    "# Extract trajectories\n",
    "dataset = extract_traj(x)\n",
    "\n",
    "# Reshape trajectories\n",
    "reshaped = np.array([i.reshape(-1) for i in dataset])\n",
    "\n",
    "# Convert to tensor (tensorflow)\n",
    "dataset = tf.cast(tf.transpose(tf.convert_to_tensor(reshaped)), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIMENSIONS ###\n",
    "\n",
    "# Number of data points (trajectories)\n",
    "num_datapoints = dataset.shape[1] #(equal to nb_points)\n",
    "\n",
    "# Dimension of trajectories: 50 coordinates (x,y) => R^100\n",
    "data_dim = dataset.shape[0]\n",
    "\n",
    "# Reduced dimension (here 11 from article results)\n",
    "latent_dim = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADVI PARAMETERS ###\n",
    "\n",
    "# Number of samples for Monte Carlo integration\n",
    "nb_samples = 30\n",
    "\n",
    "# Learning rate for step-size computation\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL DECLARATION ###\n",
    "\n",
    "advi_model = ADVI_algorithm(data_dim, latent_dim, num_datapoints, dataset, nb_samples, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Run ADVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 147988.0\n",
      "20 274656.38\n",
      "30 103773.31\n",
      "40 -48501.375\n",
      "50 -76832.81\n",
      "60 -37223.016\n",
      "70 30343.953\n",
      "80 -11266.078\n",
      "90 6467.875\n",
      "100 974.77344\n",
      "110 193.23438\n",
      "120 -1655.9062\n",
      "130 -594.46094\n",
      "140 -115.39844\n",
      "150 1021.09375\n",
      "160 -78.25781\n",
      "170 -1208.5078\n",
      "180 -1126.0625\n",
      "190 -668.5078\n",
      "200 -109.33594\n",
      "210 275.67188\n",
      "220 -502.32812\n",
      "230 -1274.2891\n",
      "240 153.32031\n",
      "250 -75.796875\n",
      "260 -67.81641\n",
      "270 -225.1211\n",
      "280 28.867188\n",
      "290 -254.76562\n",
      "300 -49.98828\n",
      "310 331.96094\n",
      "320 -291.7422\n",
      "330 -282.26953\n",
      "340 -947.97656\n",
      "350 -298.375\n",
      "360 -1073.0977\n"
     ]
    }
   ],
   "source": [
    "mu, omega = advi_model.run_ADVI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu \n",
    "pd.DataFrame(advi_model.mu.numpy()).to_csv('df/results/mu_'+str(nb_points)+'.csv',index=False)\n",
    "\n",
    "# omega \n",
    "pd.DataFrame(advi_model.omega.numpy()).to_csv('df/results/omega_'+str(nb_points)+'.csv',index=False) \n",
    "\n",
    "# ELBO evolution \n",
    "pd.DataFrame(np.array([i.numpy() for i in advi_model.elbo_evol])).to_csv('df/results/elbo_evol_'+str(nb_points)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
