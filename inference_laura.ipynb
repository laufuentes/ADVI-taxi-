{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "import pandas as pd \n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.vi import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "# Define parameters\n",
    "N = 10  # Number of datapoints\n",
    "M = 4  # Dimensionality latent variables\n",
    "D = 5  # Dimension of initial space \n",
    "\n",
    "def probas(N, M, D):\n",
    "    ###TODO: verifier que 'on veut vraiment des distributions (avec dimension comprenant les n_samples ou uni-dim)\n",
    "    with tf.compat.v1.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars = {}\n",
    "        # Prior distributions\n",
    "        # z ~ Multivariate Normal distribution\n",
    "        z_prior = tfd.MultivariateNormalFullCovariance(loc=tf.zeros([N, M]),covariance_matrix=tf.eye(M))\n",
    "        latent_vars['z_prior'] = z_prior\n",
    "        z = z_prior.sample()\n",
    "        proba_z = tf.reduce_prod(z_prior.prob(z)).numpy() # p_z\n",
    "        exp_log_proba_z = tf.reduce_prod(tf.exp(z_prior.log_prob(z))) # exp(log_p_z)\n",
    "        print(\"p_z: \", proba_z, exp_log_proba_z.numpy())\n",
    "\n",
    "        # alpha ~ Inverse Gamma distribution\n",
    "        alpha_prior = tfd.InverseGamma(concentration=1.0, scale=tf.ones(M))\n",
    "        a = alpha_prior.sample()\n",
    "        latent_vars['alpha_prior'] = alpha_prior\n",
    "        proba_alpha = tf.reduce_prod(alpha_prior.prob(a)).numpy()\n",
    "        print(\"p_alpha: \", proba_alpha)\n",
    "\n",
    "        # sigma ~ Log-normal distribution\n",
    "        sigma_prior = tfd.LogNormal(loc=0.0,scale=1.0)\n",
    "        latent_vars['sigma_prior'] = sigma_prior\n",
    "        s = sigma_prior.sample()\n",
    "        proba_sigma = sigma_prior.prob(s).numpy()\n",
    "        print(\"p_sigma: \", proba_sigma)\n",
    "\n",
    "        # w ~ Multivariate Normal distribution\n",
    "        w_prior = tfd.MultivariateNormalFullCovariance(loc=tf.zeros([D, M]),covariance_matrix=sigma_prior.sample() * tf.linalg.diag(alpha_prior.sample()))\n",
    "        latent_vars['w_prior'] = w_prior\n",
    "        w = w_prior.sample()\n",
    "        proba_w = tf.reduce_prod(w_prior.prob(w)).numpy()\n",
    "        print(\"proba_w: \", proba_w)\n",
    "\n",
    "        lik = []\n",
    "        proba_lik = 1\n",
    "        for i in range(N):\n",
    "            # Define the multivariate normal distribution\n",
    "            mvn = tfd.MultivariateNormalDiag(loc=tf.tensordot(w, z[i], axes=1), scale_diag=s * tf.ones([D]))\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            obs = mvn.sample()\n",
    "            \n",
    "            # Compute the log probability of the observation under the distribution\n",
    "            log_prob = mvn.log_prob(obs)\n",
    "            \n",
    "            # Append the observation and its log probability\n",
    "            lik.append(obs)\n",
    "            proba_lik *= tf.exp(log_prob)\n",
    "\n",
    "        # Convert proba_lik to a scalar value\n",
    "        # latent_vars['w_prior'] = w_prior\n",
    "        proba_lik = tf.squeeze(proba_lik).numpy()\n",
    "        print(\"proba_lik: \", proba_lik)\n",
    "    \n",
    "    '''  \n",
    "    print(\"proba_lik: \",proba_lik)\n",
    "    priors = [z,alpha,sigma,w, lik]\n",
    "    proba_priors = [proba_z, proba_alpha, proba_sigma, proba_w, proba_lik]\n",
    "\n",
    "    #joint distribution \n",
    "    p_theta = proba_z*proba_alpha*proba_sigma*proba_w\n",
    "    jd = p_theta*proba_lik\n",
    "    print(\"p_jd: \",jd)'''\n",
    "    return latent_vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_process(n_samples, data, latent_variables): \n",
    "    # Initialize log probabilities\n",
    "    p_log_prob = tf.constant(0.0, shape=(n_samples,))\n",
    "    q_log_prob = tf.constant(0.0, shape=(n_samples,))\n",
    "\n",
    "    base_scope = tf.Graph().as_default().unique_name(\"inference\") + '/'\n",
    "\n",
    "    for s in range(n_samples): \n",
    "        scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "        dict_swap = {}\n",
    "        # Iterate over observed variables\n",
    "        for x, qx in data.items():\n",
    "            if isinstance(x, tfp.distributions.Distribution):\n",
    "                with tf.name_scope(scope): \n",
    "                    # Construct a new random variable with the same distribution \n",
    "                    qx_copy = tf.identity(qx)\n",
    "                dict_swap[x] = qx_copy.sample()\n",
    "                \n",
    "        # Iterate over latent variables\n",
    "        for z, qz in latent_variables.items():\n",
    "            with tf.name_scope(scope):  # Ensure unique scope for each latent variable\n",
    "                qz_copy = tf.identity(qz)\n",
    "            dict_swap[z] = qz_copy.sample()\n",
    "            if hasattr(qz_copy, 'log_prob'):  # Check if log_prob function exists\n",
    "                q_log_prob[s] += tf.reduce_sum(inference.scale.get(z, 1.0) * qz_copy.log_prob(dict_swap[z]))\n",
    "            \n",
    "            # Option a moi\n",
    "            z_copy = create_copy(z, dict_swap, scope=scope)\n",
    "            if hasattr(z_copy, 'log_prob'):  # Check if log_prob function exists\n",
    "                p_log_prob[s] += tf.reduce_sum(inference.scale.get(z, 1.0) * z_copy.log_prob(z_copy.value()))\n",
    "\n",
    "            # Option nouvelle \n",
    "        '''  for z, _ in latent_vars.items():\n",
    "        z_copy = create_copy(z, dict_swap, scope=scope)\n",
    "        if hasattr(z_copy, 'log_prob'):  # Check if log_prob function exists\n",
    "                p_log_prob[s] += tf.reduce_sum(inference.scale.get(z, 1.0) * z_copy.log_prob(z_copy.value()))\n",
    "    '''\n",
    "        \n",
    "        for x, _ in data.items():\n",
    "            x_copy = create_copy(x, dict_swap, scope=scope)\n",
    "            p_log_prob[s] += tf.reduce_sum(\n",
    "                inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "            \n",
    "    # Update log probabilities\n",
    "    p_log_prob = tf.reduce_mean(p_log_prob)\n",
    "    q_log_prob = tf.reduce_mean(q_log_prob)\n",
    "    reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "    losses = p_log_prob - q_log_prob\n",
    "    loss = -(p_log_prob - q_log_prob - reg_penalty)\n",
    "\n",
    "    q_vars = [v for v in var_list if len(get_descendants(tf.convert_to_tensor(v), q_rvs)) != 0]\n",
    "    q_grads = tf.gradients(-(tf.reduce_mean(q_log_prob * tf.stop_gradient(losses)) - reg_penalty),q_vars)\n",
    "    p_vars = [v for v in var_list if v not in q_vars]\n",
    "    p_grads = tf.gradients(loss, p_vars)\n",
    "    grads_and_vars = list(zip(q_grads, q_vars)) + list(zip(p_grads, p_vars))\n",
    "    \n",
    "    return  loss, grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.inferences.variational_inference import VariationalInference\n",
    "from edward.models import RandomVariable\n",
    "from edward.util import copy, get_descendants\n",
    "\n",
    "\n",
    "  ild_reparam_kl_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ReparameterizationEntropyKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "\n",
    "  This class minimizes the objective using the reparameterization\n",
    "  gradient and an analytic entropy term.\n",
    "\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ReparameterizationEntropyKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ReparameterizationEntropyKLqp, self).initialize(\n",
    "        *args, **kwargs)\n",
    "\n",
    "\n",
    "class ScoreKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "\n",
    "  This class minimizes the objective using the score function\n",
    "  gradient.\n",
    "\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ScoreKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreKLKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "\n",
    "  This class minimizes the objective using the score function gradient\n",
    "  and an analytic KL term.\n",
    "\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreKLKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, kl_scaling=None, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "      kl_scaling: dict of RandomVariable to tf.Tensor.\n",
    "        Provides option to scale terms when using ELBO with KL divergence.\n",
    "        If the KL divergence terms are\n",
    "\n",
    "        $\\\\alpha_p \\mathbb{E}_{q(z\\mid x, \\lambda)} [\n",
    "              \\log q(z\\mid x, \\lambda) - \\log p(z)],$\n",
    "\n",
    "        then pass {$p(z)$: $\\\\alpha_p$} as `kl_scaling`,\n",
    "        where $\\\\alpha_p$ is a tensor. Its shape must be broadcastable;\n",
    "        it is multiplied element-wise to the batchwise KL terms.\n",
    "    \"\"\"\n",
    "    if kl_scaling is None:\n",
    "      kl_scaling = {}\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    self.kl_scaling = kl_scaling\n",
    "    return super(ScoreKLKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_kl_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreEntropyKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "\n",
    "  This class minimizes the objective using the score function gradient\n",
    "  and an analytic entropy term.\n",
    "\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreEntropyKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ScoreEntropyKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_entropy_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "\n",
    "def build_reparam_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function. Its automatic differentiation\n",
    "  is a stochastic gradient of\n",
    "\n",
    "  $-\\\\text{ELBO} =\n",
    "      -\\mathbb{E}_{q(z; \\lambda)} [ \\log p(x, z) - \\log q(z; \\lambda) ]$\n",
    "\n",
    "  based on the reparameterization trick [@kingma2014auto].\n",
    "\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  \n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")     #creates a scope named \"inference\" with a unique identifier appended to it\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * qz_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.reduce_mean(p_log_prob)\n",
    "  q_log_prob = tf.reduce_mean(q_log_prob)\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", p_log_prob,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", q_log_prob,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(p_log_prob - q_log_prob - reg_penalty)\n",
    "\n",
    "  grads = tf.gradients(loss, var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_reparam_kl_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function. Its automatic differentiation\n",
    "  is a stochastic gradient of\n",
    "\n",
    "  .. math::\n",
    "\n",
    "    -\\\\text{ELBO} =  - ( \\mathbb{E}_{q(z; \\lambda)} [ \\log p(x \\mid z) ]\n",
    "          + \\\\text{KL}(q(z; \\lambda) \\| p(z)) )\n",
    "\n",
    "  based on the reparameterization trick [@kingma2014auto].\n",
    "\n",
    "  It assumes the KL is analytic.\n",
    "\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_lik = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_lik[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_lik = tf.reduce_mean(p_log_lik)\n",
    "\n",
    "  kl_penalty = tf.reduce_sum([\n",
    "      tf.reduce_sum(inference.kl_scaling.get(z, 1.0) * kl_divergence(qz, z))\n",
    "      for z, qz in six.iteritems(inference.latent_vars)])\n",
    "\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_lik\", p_log_lik,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/kl_penalty\", kl_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(p_log_lik - kl_penalty - reg_penalty)\n",
    "\n",
    "  grads = tf.gradients(loss, var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "def build_score_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator [@paisley2012variational].\n",
    "\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.stack(p_log_prob)\n",
    "  q_log_prob = tf.stack(q_log_prob)\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", tf.reduce_mean(p_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", tf.reduce_mean(q_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  losses = p_log_prob - q_log_prob\n",
    "  loss = -(tf.reduce_mean(losses) - reg_penalty)\n",
    "\n",
    "  q_rvs = list(six.itervalues(inference.latent_vars))\n",
    "  q_vars = [v for v in var_list\n",
    "            if len(get_descendants(tf.convert_to_tensor(v), q_rvs)) != 0]\n",
    "  q_grads = tf.gradients(\n",
    "      -(tf.reduce_mean(q_log_prob * tf.stop_gradient(losses)) - reg_penalty),\n",
    "      q_vars)\n",
    "  p_vars = [v for v in var_list if v not in q_vars]\n",
    "  p_grads = tf.gradients(loss, p_vars)\n",
    "  grads_and_vars = list(zip(q_grads, q_vars)) + list(zip(p_grads, p_vars))\n",
    "  return loss, grads_and_vars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
